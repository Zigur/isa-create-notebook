{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ISA-API Investigation from Study Design configuration\n",
    "\n",
    "In this notebook I will show you how you can use a study design configuration is JSON format to generate a single-study ISA investigation and how you can then serialise it in JSON and tabular (i.e. CSV) format.\n",
    "\n",
    "Or study design configuration consists of:\n",
    "* two study arms (treatment and control)\n",
    "* blood and liver samples are taken during the treatment phase\n",
    "* blood samples are used to perform Metabolite Profiling with two assays: mass spectrometry and nuclear magnetic resonance (NMR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Let's import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massi/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/create/models.py:101: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_config = yaml.load(yaml_file)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "## ISA-API related imports\n",
    "from isatools.model import Investigation, Study\n",
    "\n",
    "## ISA-API create mode related imports\n",
    "from isatools.create.models import StudyDesign\n",
    "from isatools.create.connectors import generate_isa_study_design_from_datascriptor_config\n",
    "\n",
    "# serializer from ISA Investigation to JSON\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "\n",
    "# ISA-Tab serialisation\n",
    "from isatools import isatab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Study Design JSON configuration\n",
    "\n",
    "First of all we load the study design configurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'here you can describe your type of design',\n",
       " 'elements': [{'id': '#element/screen',\n",
       "   'name': 'screen',\n",
       "   'type': 'screen',\n",
       "   'duration': 7,\n",
       "   'durationUnit': 'days'},\n",
       "  {'id': '#element/first_treatment',\n",
       "   'name': 'first treatment',\n",
       "   'type': 'chemical intervention',\n",
       "   'agent': 'test drug',\n",
       "   'intensity': 10,\n",
       "   'intensityUnit': 'mg/day',\n",
       "   'duration': 30,\n",
       "   'durationUnit': 'days'},\n",
       "  {'id': '#element/surgical_treatment',\n",
       "   'name': 'surgical treatment',\n",
       "   'type': 'surgical intervention',\n",
       "   'agent': 'surgery'},\n",
       "  {'id': '#element/follow-up',\n",
       "   'name': 'follow-up',\n",
       "   'type': 'follow-up',\n",
       "   'duration': 3,\n",
       "   'durationUnit': 'months'},\n",
       "  {'id': '#element/control_treatment',\n",
       "   'name': 'control treatment',\n",
       "   'type': 'chemical intervention',\n",
       "   'agent': 'placebo',\n",
       "   'intensity': 10,\n",
       "   'intensityUnit': 'mg/day',\n",
       "   'duration': 30,\n",
       "   'durationUnit': 'days'}],\n",
       " 'events': [{'id': '#event/sampling_0',\n",
       "   'action': 'sampling',\n",
       "   'input': 'subject',\n",
       "   'output': 'liver sample',\n",
       "   'outputSize': 1},\n",
       "  {'id': '#event/sampling_1',\n",
       "   'action': 'sampling',\n",
       "   'input': 'subject',\n",
       "   'output': 'blood sample',\n",
       "   'outputSize': 3},\n",
       "  {'id': '#event/assay_0',\n",
       "   'action': 'assay',\n",
       "   'template': {'measurement_type': 'metabolite profiling',\n",
       "    'technology_type': 'mass spectrometry',\n",
       "    'workflow': [['extraction', {}],\n",
       "     ['extract',\n",
       "      [{'node_type': 'extract',\n",
       "        'characteristics_category': 'extract type',\n",
       "        'characteristics_value': 'polar fraction',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': True},\n",
       "       {'node_type': 'extract',\n",
       "        'characteristics_category': 'extract type',\n",
       "        'characteristics_value': 'lipids',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': True}]],\n",
       "     ['labelling', {'#replicates': 2}],\n",
       "     ['labelled extract',\n",
       "      [{'node_type': 'labeled extract',\n",
       "        'characteristics_category': 'labelled extract type',\n",
       "        'characteristics_value': '',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': True}]],\n",
       "     ['mass spectrometry',\n",
       "      {'#replicates': 2,\n",
       "       'instrument': ['Agilent QTQF 6510'],\n",
       "       'injection_mode': ['FIA', 'LC'],\n",
       "       'acquisition_mode': ['positive mode']}],\n",
       "     ['raw spectral data file',\n",
       "      [{'node_type': 'data file',\n",
       "        'size': 2,\n",
       "        'is_input_to_next_protocols': False}]]]}},\n",
       "  {'id': '#event/assay_1',\n",
       "   'action': 'assay',\n",
       "   'template': {'measurement_type': 'metabolite profiling',\n",
       "    'technology_type': 'nmr spectroscopy',\n",
       "    'workflow': [['extraction', {}],\n",
       "     ['extract',\n",
       "      [{'node_type': 'extract',\n",
       "        'characteristics_category': 'extract type',\n",
       "        'characteristics_value': 'supernatant',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': True},\n",
       "       {'node_type': 'extract',\n",
       "        'characteristics_category': 'extract type',\n",
       "        'characteristics_value': 'pellet',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': True}]],\n",
       "     ['nmr spectroscopy',\n",
       "      {'#replicates': 2,\n",
       "       'instrument': ['Bruker AvanceII 1 GHz'],\n",
       "       'pulse_sequence': ['CPMG', 'watergate'],\n",
       "       'acquisition_mode': ['1D 13C NMR', '2D 13C-13C NMR']}],\n",
       "     ['raw spectral data file',\n",
       "      [{'node_type': 'data file',\n",
       "        'size': 1,\n",
       "        'is_input_to_next_protocols': False}]]]}}],\n",
       " 'arms': [{'id': '#arm/treatment',\n",
       "   'name': 'treatment',\n",
       "   'subjectType': 'Human',\n",
       "   'size': 10,\n",
       "   'epochs': [{'elements': ['#element/screen'], 'events': []},\n",
       "    {'elements': ['#element/first_treatment'], 'events': []},\n",
       "    {'elements': ['#element/surgical_treatment'],\n",
       "     'events': ['#event/sampling_0', '#event/assay_0']},\n",
       "    {'elements': ['#element/follow-up'],\n",
       "     'events': ['#event/sampling_1', '#event/assay_0', '#event/assay_1']}]},\n",
       "  {'id': '#arm/control',\n",
       "   'name': 'control',\n",
       "   'subjectType': 'Homo Sapiens',\n",
       "   'size': 8,\n",
       "   'epochs': [{'elements': ['#element/screen'], 'events': []},\n",
       "    {'elements': ['#element/control_treatment'], 'events': []},\n",
       "    {'elements': [], 'events': []},\n",
       "    {'elements': ['#element/follow-up'],\n",
       "     'events': ['#event/sampling_1', '#event/assay_0', '#event/assay_1']}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.abspath(os.path.join(\"config\", \"study-design-with-two-arms-datascriptor.json\")), \"r\") as config_file:\n",
    "    study_design_config = json.load(config_file)\n",
    "study_design_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate the ISA Study Design from the JSON configuration\n",
    "To perform the conversion we just need to use the function `generate_isa_study_design_from_datascriptor_config` (name possibly subject to change, should we drop the \"isa\" and \"datascriptor\" qualifiers?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extraction_000\n",
      "count: 0, prev_node: extraction_000\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "count: 0, prev_node: labelling_000_000\n",
      "count: 1, prev_node: labelling_000_001\n",
      "{isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]): ['Agilent QTQF 6510'], isatools.model.OntologyAnnotation(term='injection_mode', term_source=None, term_accession='', comments=[]): ['FIA', 'LC'], isatools.model.OntologyAnnotation(term='acquisition_mode', term_source=None, term_accession='', comments=[]): ['positive mode']}\n",
      "pv_combination: ('Agilent QTQF 6510', 'FIA', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "pv_combination: ('Agilent QTQF 6510', 'LC', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "count: 0, prev_node: mass_spectrometry_000_000\n",
      "count: 1, prev_node: mass_spectrometry_000_001\n",
      "count: 2, prev_node: mass_spectrometry_001_000\n",
      "count: 3, prev_node: mass_spectrometry_001_001\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extraction_000\n",
      "count: 0, prev_node: extraction_000\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "count: 0, prev_node: labelling_000_000\n",
      "count: 1, prev_node: labelling_000_001\n",
      "{isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]): ['Agilent QTQF 6510'], isatools.model.OntologyAnnotation(term='injection_mode', term_source=None, term_accession='', comments=[]): ['FIA', 'LC'], isatools.model.OntologyAnnotation(term='acquisition_mode', term_source=None, term_accession='', comments=[]): ['positive mode']}\n",
      "pv_combination: ('Agilent QTQF 6510', 'FIA', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "pv_combination: ('Agilent QTQF 6510', 'LC', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "count: 0, prev_node: mass_spectrometry_000_000\n",
      "count: 1, prev_node: mass_spectrometry_000_001\n",
      "count: 2, prev_node: mass_spectrometry_001_000\n",
      "count: 3, prev_node: mass_spectrometry_001_001\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extraction_000\n",
      "count: 0, prev_node: extraction_000\n",
      "{isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]): ['Bruker AvanceII 1 GHz'], isatools.model.OntologyAnnotation(term='pulse_sequence', term_source=None, term_accession='', comments=[]): ['CPMG', 'watergate'], isatools.model.OntologyAnnotation(term='acquisition_mode', term_source=None, term_accession='', comments=[]): ['1D 13C NMR', '2D 13C-13C NMR']}\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'CPMG', '1D 13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'CPMG', '2D 13C-13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'watergate', '1D 13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'watergate', '2D 13C-13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "count: 0, prev_node: nmr_spectroscopy_000_000\n",
      "count: 1, prev_node: nmr_spectroscopy_000_001\n",
      "count: 2, prev_node: nmr_spectroscopy_001_000\n",
      "count: 3, prev_node: nmr_spectroscopy_001_001\n",
      "count: 4, prev_node: nmr_spectroscopy_002_000\n",
      "count: 5, prev_node: nmr_spectroscopy_002_001\n",
      "count: 6, prev_node: nmr_spectroscopy_003_000\n",
      "count: 7, prev_node: nmr_spectroscopy_003_001\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extraction_000\n",
      "count: 0, prev_node: extraction_000\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "count: 0, prev_node: labelling_000_000\n",
      "count: 1, prev_node: labelling_000_001\n",
      "{isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]): ['Agilent QTQF 6510'], isatools.model.OntologyAnnotation(term='injection_mode', term_source=None, term_accession='', comments=[]): ['FIA', 'LC'], isatools.model.OntologyAnnotation(term='acquisition_mode', term_source=None, term_accession='', comments=[]): ['positive mode']}\n",
      "pv_combination: ('Agilent QTQF 6510', 'FIA', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "pv_combination: ('Agilent QTQF 6510', 'LC', 'positive mode')\n",
      "count: 0, prev_node: labelled_extract_000_000\n",
      "count: 1, prev_node: labelled_extract_000_001\n",
      "count: 0, prev_node: mass_spectrometry_000_000\n",
      "count: 1, prev_node: mass_spectrometry_000_001\n",
      "count: 2, prev_node: mass_spectrometry_001_000\n",
      "count: 3, prev_node: mass_spectrometry_001_001\n",
      "{}\n",
      "pv_combination: ()\n",
      "count: 0, prev_node: extraction_000\n",
      "count: 0, prev_node: extraction_000\n",
      "{isatools.model.OntologyAnnotation(term='instrument', term_source=None, term_accession='', comments=[]): ['Bruker AvanceII 1 GHz'], isatools.model.OntologyAnnotation(term='pulse_sequence', term_source=None, term_accession='', comments=[]): ['CPMG', 'watergate'], isatools.model.OntologyAnnotation(term='acquisition_mode', term_source=None, term_accession='', comments=[]): ['1D 13C NMR', '2D 13C-13C NMR']}\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'CPMG', '1D 13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'CPMG', '2D 13C-13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'watergate', '1D 13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "pv_combination: ('Bruker AvanceII 1 GHz', 'watergate', '2D 13C-13C NMR')\n",
      "count: 0, prev_node: extract_000_000\n",
      "count: 1, prev_node: extract_001_000\n",
      "count: 0, prev_node: nmr_spectroscopy_000_000\n",
      "count: 1, prev_node: nmr_spectroscopy_000_001\n",
      "count: 2, prev_node: nmr_spectroscopy_001_000\n",
      "count: 3, prev_node: nmr_spectroscopy_001_001\n",
      "count: 4, prev_node: nmr_spectroscopy_002_000\n",
      "count: 5, prev_node: nmr_spectroscopy_002_001\n",
      "count: 6, prev_node: nmr_spectroscopy_003_000\n",
      "count: 7, prev_node: nmr_spectroscopy_003_001\n"
     ]
    }
   ],
   "source": [
    "study_design = generate_isa_study_design_from_datascriptor_config(study_design_config)\n",
    "assert isinstance(study_design, StudyDesign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate the ISA Study from the StudyDesign and embed it into an ISA Investigation\n",
    "\n",
    "The `StudyDesign.generate_isa_study()` method returns the complete ISA-API `Study` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/massi/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/create/models.py:2337: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling protocol is Protocol(\n",
      "    name=sample collection\n",
      "    protocol_type=sample_collection\n",
      "    uri=\n",
      "    version=\n",
      "    parameters=2 ProtocolParameter objects\n",
      "    components=0 OntologyAnnotation objects\n",
      "    comments=0 Comment objects\n",
      ")\n",
      "The generation of the study design took 1.83 s.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "study = study_design.generate_isa_study()\n",
    "end = time()\n",
    "print('The generation of the study design took {:.2f} s.'.format(end - start))\n",
    "assert isinstance(study, Study)\n",
    "investigation = Investigation(studies=[study])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Serialize and save the JSON representation of the generated ISA Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON serialisation of the study design took 0.42 s.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "inv_json = json.dumps(investigation, cls=ISAJSONEncoder, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "end = time()\n",
    "print('The JSON serialisation of the ISA investigation took {:.2f} s.'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.abspath(os.path.join('output'))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(os.path.abspath(os.path.join('output','isa-investigation-2-arms-nmr-ms.json')), 'w') as out_fp:\n",
    "    json.dump(json.loads(inv_json), out_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dump the ISA Investigation to ISA-Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-06 18:26:47,803 [INFO]: model.py(graph:1544) >> Building graph for object: Study(\n",
      "    identifier=\n",
      "    filename=s_study_01.txt\n",
      "    title=\n",
      "    description=\n",
      "    submission_date=\n",
      "    public_release_date=\n",
      "    contacts=0 Person objects\n",
      "    design_descriptors=0 OntologyAnnotation objects\n",
      "    publications=0 Publication objects\n",
      "    factors=3 StudyFactor objects\n",
      "    protocols=16 Protocol objects\n",
      "    assays=5 Assay objects\n",
      "    sources=18 Source objects\n",
      "    samples=64 Sample objects\n",
      "    process_sequence=64 Process objects\n",
      "    other_material=0 Material objects\n",
      "    characteristic_categories=0 OntologyAnnots\n",
      "    comments=0 Comment objects\n",
      "    units=0 Unit objects\n",
      ")\n",
      "2020-05-06 18:26:47,847 [INFO]: model.py(graph:1544) >> Building graph for object: Study(\n",
      "    identifier=\n",
      "    filename=s_study_01.txt\n",
      "    title=\n",
      "    description=\n",
      "    submission_date=\n",
      "    public_release_date=\n",
      "    contacts=0 Person objects\n",
      "    design_descriptors=0 OntologyAnnotation objects\n",
      "    publications=0 Publication objects\n",
      "    factors=3 StudyFactor objects\n",
      "    protocols=16 Protocol objects\n",
      "    assays=5 Assay objects\n",
      "    sources=18 Source objects\n",
      "    samples=64 Sample objects\n",
      "    process_sequence=64 Process objects\n",
      "    other_material=0 Material objects\n",
      "    characteristic_categories=0 OntologyAnnots\n",
      "    comments=0 Comment objects\n",
      "    units=0 Unit objects\n",
      ")\n",
      "2020-05-06 18:26:47,890 [INFO]: model.py(graph:1544) >> Building graph for object: Study(\n",
      "    identifier=\n",
      "    filename=s_study_01.txt\n",
      "    title=\n",
      "    description=\n",
      "    submission_date=\n",
      "    public_release_date=\n",
      "    contacts=0 Person objects\n",
      "    design_descriptors=0 OntologyAnnotation objects\n",
      "    publications=0 Publication objects\n",
      "    factors=3 StudyFactor objects\n",
      "    protocols=16 Protocol objects\n",
      "    assays=5 Assay objects\n",
      "    sources=18 Source objects\n",
      "    samples=64 Sample objects\n",
      "    process_sequence=64 Process objects\n",
      "    other_material=0 Material objects\n",
      "    characteristic_categories=0 OntologyAnnots\n",
      "    comments=0 Comment objects\n",
      "    units=0 Unit objects\n",
      ")\n",
      "2020-05-06 18:26:48,060 [INFO]: isatab.py(_all_end_to_end_paths:1152) >> Found 64 paths!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'term'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-917f1a18ee0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0misatools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misatab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0misatab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The Tab serialisation of the ISA investigation took {:.2f} s.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(isa_obj, output_path, i_file_name, skip_dump_tables, write_factor_values_in_assay_table)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mwrite_study_table_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvestigation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m         write_assay_table_files(\n\u001b[1;32m   1049\u001b[0m             investigation, output_path, write_factor_values_in_assay_table)\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mwrite_study_table_files\u001b[0;34m(inv_obj, output_dir)\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 columns += flatten(\n\u001b[1;32m   1219\u001b[0m                     map(lambda x: get_characteristic_columns(olabel, x),\n\u001b[0;32m-> 1220\u001b[0;31m                         node.characteristics))\n\u001b[0m\u001b[1;32m   1221\u001b[0m                 columns += flatten(\n\u001b[1;32m   1222\u001b[0m                     map(lambda x: get_comment_column(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mprotnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mprotnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1217\u001b[0m                 \u001b[0msample_in_path_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 columns += flatten(\n\u001b[0;32m-> 1219\u001b[0;31m                     map(lambda x: get_characteristic_columns(olabel, x),\n\u001b[0m\u001b[1;32m   1220\u001b[0m                         node.characteristics))\n\u001b[1;32m   1221\u001b[0m                 columns += flatten(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/isa-create-notebook-3.7.5/src/isatools/isatools/isatab.py\u001b[0m in \u001b[0;36mget_characteristic_columns\u001b[0;34m(label, c)\u001b[0m\n\u001b[1;32m   1665\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1666\u001b[0m     \"\"\"\n\u001b[0;32m-> 1667\u001b[0;31m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"{0}.Characteristics[{1}]\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1668\u001b[0m     \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_value_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1669\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'term'"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "isatab.dump(investigation, os.path.abspath(os.path.join('output')))\n",
    "end = time()\n",
    "print('The Tab serialisation of the ISA investigation took {:.2f} s.'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use them on the notebook we can also dump the tables to pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = isatab.dump_tables_to_dataframes(investigation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
